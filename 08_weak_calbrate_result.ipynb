{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Реализация в Pose2Sim калибровки камер"
      ],
      "metadata": {
        "id": "oGZA5Dkgu4vK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Клонируем репозиторий pose2sim\n",
        "!git clone --depth 1 https://github.com/perfanalytics/pose2sim.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IMU_JilUvDIm",
        "outputId": "2b553f89-a354-4b3a-d494-04a73a187145"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'pose2sim'...\n",
            "remote: Enumerating objects: 406, done.\u001b[K\n",
            "remote: Counting objects: 100% (406/406), done.\u001b[K\n",
            "remote: Compressing objects: 100% (389/389), done.\u001b[K\n",
            "remote: Total 406 (delta 42), reused 332 (delta 12), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (406/406), 37.99 MiB | 25.41 MiB/s, done.\n",
            "Resolving deltas: 100% (42/42), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mpl_interactions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C26Xghp3vvRv",
        "outputId": "3b245c22-6eab-4d07-ef44-d83462746935"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mpl_interactions\n",
            "  Downloading mpl_interactions-0.24.2-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: matplotlib>=3.7 in /usr/local/lib/python3.10/dist-packages (from mpl_interactions) (3.8.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7->mpl_interactions) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7->mpl_interactions) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7->mpl_interactions) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7->mpl_interactions) (1.4.7)\n",
            "Requirement already satisfied: numpy<2,>=1.21 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7->mpl_interactions) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7->mpl_interactions) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7->mpl_interactions) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7->mpl_interactions) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7->mpl_interactions) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.7->mpl_interactions) (1.17.0)\n",
            "Downloading mpl_interactions-0.24.2-py3-none-any.whl (45 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/45.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: mpl_interactions\n",
            "Successfully installed mpl_interactions-0.24.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import logging\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "os.environ[\"OPENCV_LOG_LEVEL\"]=\"FATAL\"\n",
        "import cv2\n",
        "import glob\n",
        "import toml\n",
        "import re\n",
        "from lxml import etree\n",
        "import warnings\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_interactions import zoom_factory, panhandler\n",
        "from PIL import Image\n",
        "from contextlib import contextmanager,redirect_stderr,redirect_stdout\n",
        "from os import devnull\n",
        "import time\n",
        "from datetime import datetime"
      ],
      "metadata": {
        "id": "AGK20vtVvqI6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Реализация в Pose2Sim получение уровня и списка конфигурационных словарей\n",
        "import os\n",
        "import toml\n",
        "from copy import deepcopy\n",
        "\n",
        "config_dir = '/content/pose2sim/Pose2Sim/Demo_SinglePerson/'\n",
        "\n",
        "project_dir = '/content/pose2sim/Pose2Sim/Demo_SinglePerson/'\n",
        "\n",
        "def recursive_update(dict_to_update, dict_with_new_values):\n",
        "    '''\n",
        "    Обновляет вложенные словари, не перезаписывая существующие ключи на любом уровне вложенности.\n",
        "\n",
        "    Пример:\n",
        "    dict_to_update = {'key': {'key_1': 'val_1', 'key_2': 'val_2'}}\n",
        "    dict_with_new_values = {'key': {'key_1': 'val_1_new'}}\n",
        "    возвращает {'key': {'key_1': 'val_1_new', 'key_2': 'val_2'}}\n",
        "    в то время как dict_to_update.update(dict_with_new_values) вернет {'key': {'key_1': 'val_1_new'}}\n",
        "    '''\n",
        "\n",
        "    # Проходим по всем ключам и значениям в словаре с новыми значениями\n",
        "    for key, value in dict_with_new_values.items():\n",
        "        # Проверяем, существует ли ключ в словаре для обновления и является ли значение словарем\n",
        "        if key in dict_to_update and isinstance(value, dict) and isinstance(dict_to_update[key], dict):\n",
        "            # Рекурсивно обновляем вложенные словари\n",
        "            dict_to_update[key] = recursive_update(dict_to_update[key], value)\n",
        "        else:\n",
        "            # Обновляем или добавляем новые пары ключ-значение\n",
        "            dict_to_update[key] = value\n",
        "\n",
        "    # Возвращаем обновленный словарь\n",
        "    return dict_to_update\n",
        "\n",
        "def determine_level(config_dir):\n",
        "    '''\n",
        "    Определяет уровень, на котором вызывается функция.\n",
        "    Уровень = 1: Папка испытания (Trial folder)\n",
        "    Уровень = 2: Корневая папка (Root folder)\n",
        "    '''\n",
        "\n",
        "    # Создаем список, в котором храним длину пути для каждой папки,\n",
        "    # содержащей файл 'Config.toml'. Длина пути определяется количеством\n",
        "    # разделителей в пути (os.sep).\n",
        "    len_paths = [len(root.split(os.sep)) for root, dirs, files in os.walk(config_dir) if 'Config.toml' in files]\n",
        "\n",
        "    # Если список len_paths пуст, это означает, что не найдено ни одного файла 'Config.toml'.\n",
        "    # В этом случае выбрасываем исключение FileNotFoundError с соответствующим сообщением.\n",
        "    if len_paths == []:\n",
        "        raise FileNotFoundError('Вам нужен файл Config.toml в каждой папке испытания или корневой папке.')\n",
        "\n",
        "    # Определяем уровень, вычисляя разницу между максимальной и минимальной длиной пути,\n",
        "    # добавляя 1, чтобы учесть уровень.\n",
        "    level = max(len_paths) - min(len_paths) + 1\n",
        "\n",
        "    # Возвращаем определенный уровень.\n",
        "    return level\n",
        "\n",
        "\n",
        "def read_config_files(config=None, config_dir='/content/pose2sim/Pose2Sim/Demo_SinglePerson/'):\n",
        "    '''\n",
        "    Читает корневые и пробные конфигурационные файлы\n",
        "    и возвращает словарь со всеми параметрами.\n",
        "    '''\n",
        "\n",
        "    if type(config) == dict:\n",
        "        level = 2  # Уровень 2, логическая директория = текущая рабочая директория\n",
        "        config_dicts = [config]\n",
        "        if config_dicts[0].get('project').get('project_dir') is None:\n",
        "            raise ValueError('Пожалуйста, укажите директорию проекта в config_dict:\\n \\\n",
        "                             config_dict.get(\"project\").update({\"project_dir\":\"<ВАША_ДИРЕКТОРИЯ_ПРОЕКТА>\"})')\n",
        "    else:\n",
        "        # Если вызван без аргумента, config == None, иначе это путь к директории конфигурации\n",
        "        config_dir = config_dir if config is None else config  # Используем config_dir\n",
        "        level = determine_level(config_dir)  # Определяем уровень конфигурации\n",
        "\n",
        "        # Уровень пробного испытания\n",
        "        if level == 1:  # Уровень пробного испытания\n",
        "            try:\n",
        "                # Если пакетная обработка\n",
        "                session_config_dict = toml.load(os.path.join(config_dir, '..', 'Config.toml'))\n",
        "                trial_config_dict = toml.load(os.path.join(config_dir, 'Config.toml'))\n",
        "                session_config_dict = recursive_update(session_config_dict, trial_config_dict)  # Обновляем словарь сессии\n",
        "            except:\n",
        "                # Если одно пробное испытание\n",
        "                session_config_dict = toml.load(os.path.join(config_dir, 'Config.toml'))\n",
        "            session_config_dict.get(\"project\").update({\"project_dir\": config_dir})  # Устанавливаем директорию проекта\n",
        "            config_dicts = [session_config_dict]  # Сохраняем конфигурацию сессии в список\n",
        "\n",
        "        # Корневой уровень\n",
        "        if level == 2:\n",
        "            session_config_dict = toml.load(os.path.join(config_dir, 'Config.toml'))  # Загружаем корневую конфигурацию\n",
        "            config_dicts = []\n",
        "            # Создаем конфигурационные словари для всех пробных испытаний участника\n",
        "            for (root, dirs, files) in os.walk(config_dir):\n",
        "                if 'Config.toml' in files and root != config_dir:\n",
        "                    trial_config_dict = toml.load(os.path.join(root, 'Config.toml'))  # Загружаем конфигурацию пробного испытания\n",
        "                    # Глубокое копирование, иначе session_config_dict изменяется на каждой итерации в списке config_dicts\n",
        "                    temp_dict = deepcopy(session_config_dict)\n",
        "                    temp_dict = recursive_update(temp_dict, trial_config_dict)  # Обновляем временный словарь\n",
        "                    temp_dict.get(\"project\").update({\"project_dir\": os.path.join(config_dir, os.path.relpath(root))})  # Устанавливаем директорию проекта для пробного испытания\n",
        "                    if not os.path.basename(root) in temp_dict.get(\"project\").get('exclude_from_batch'):\n",
        "                        config_dicts.append(temp_dict)  # Добавляем временный словарь в список конфигураций\n",
        "\n",
        "    return level, config_dicts  # Возвращаем уровень и список конфигурационных словарей\n",
        "\n",
        "\n",
        "level, config_dicts = read_config_files(config=None, config_dir=config_dir)\n",
        "config_dict = config_dicts[0]\n"
      ],
      "metadata": {
        "id": "piHi7FS7l27a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config_dict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KDiIGmQIqv-M",
        "outputId": "f67575a5-d37d-4758-83a8-57745460c2d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'project': {'multi_person': False,\n",
              "  'participant_height': 1.72,\n",
              "  'participant_mass': 70.0,\n",
              "  'frame_rate': 'auto',\n",
              "  'frame_range': [],\n",
              "  'exclude_from_batch': [],\n",
              "  'project_dir': '/content/pose2sim/Pose2Sim/Demo_SinglePerson/'},\n",
              " 'pose': {'vid_img_extension': 'mp4',\n",
              "  'pose_model': 'HALPE_26',\n",
              "  'mode': 'balanced',\n",
              "  'det_frequency': 1,\n",
              "  'display_detection': True,\n",
              "  'overwrite_pose': False,\n",
              "  'save_video': 'to_video',\n",
              "  'output_format': 'openpose',\n",
              "  'CUSTOM': {'name': 'Hip',\n",
              "   'id': '19',\n",
              "   'children': [{'name': 'RHip',\n",
              "     'id': 12,\n",
              "     'children': [{'name': 'RKnee',\n",
              "       'id': 14,\n",
              "       'children': [{'name': 'RAnkle',\n",
              "         'id': 16,\n",
              "         'children': [{'name': 'RBigToe',\n",
              "           'id': 21,\n",
              "           'children': [{'name': 'RSmallToe', 'id': 23}]},\n",
              "          {'name': 'RHeel', 'id': 25}]}]}]},\n",
              "    {'name': 'LHip',\n",
              "     'id': 11,\n",
              "     'children': [{'name': 'LKnee',\n",
              "       'id': 13,\n",
              "       'children': [{'name': 'LAnkle',\n",
              "         'id': 15,\n",
              "         'children': [{'name': 'LBigToe',\n",
              "           'id': 20,\n",
              "           'children': [{'name': 'LSmallToe', 'id': 22}]},\n",
              "          {'name': 'LHeel', 'id': 24}]}]}]},\n",
              "    {'name': 'Neck',\n",
              "     'id': 18,\n",
              "     'children': [{'name': 'Head',\n",
              "       'id': 17,\n",
              "       'children': [{'name': 'Nose', 'id': 0}]},\n",
              "      {'name': 'RShoulder',\n",
              "       'id': 6,\n",
              "       'children': [{'name': 'RElbow',\n",
              "         'id': 8,\n",
              "         'children': [{'name': 'RWrist', 'id': 10}]}]},\n",
              "      {'name': 'LShoulder',\n",
              "       'id': 5,\n",
              "       'children': [{'name': 'LElbow',\n",
              "         'id': 7,\n",
              "         'children': [{'name': 'LWrist', 'id': 9}]}]}]}]}},\n",
              " 'synchronization': {'display_sync_plots': True,\n",
              "  'keypoints_to_consider': ['RWrist'],\n",
              "  'approx_time_maxspeed': 'auto',\n",
              "  'time_range_around_maxspeed': 2.0,\n",
              "  'likelihood_threshold': 0.4,\n",
              "  'filter_cutoff': 6,\n",
              "  'filter_order': 4},\n",
              " 'calibration': {'calibration_type': 'convert',\n",
              "  'convert': {'convert_from': 'qualisys',\n",
              "   'caliscope': {},\n",
              "   'qualisys': {'binning_factor': 1},\n",
              "   'optitrack': {},\n",
              "   'vicon': {},\n",
              "   'opencap': {},\n",
              "   'easymocap': {},\n",
              "   'biocv': {},\n",
              "   'anipose': {},\n",
              "   'freemocap': {}},\n",
              "  'calculate': {'intrinsics': {'overwrite_intrinsics': False,\n",
              "    'show_detection_intrinsics': True,\n",
              "    'intrinsics_extension': 'jpg',\n",
              "    'extract_every_N_sec': 1,\n",
              "    'intrinsics_corners_nb': [4, 7],\n",
              "    'intrinsics_square_size': 60},\n",
              "   'extrinsics': {'calculate_extrinsics': True,\n",
              "    'extrinsics_method': 'scene',\n",
              "    'moving_cameras': False,\n",
              "    'board': {'show_reprojection_error': True,\n",
              "     'extrinsics_extension': 'png',\n",
              "     'extrinsics_corners_nb': [4, 7],\n",
              "     'extrinsics_square_size': 60},\n",
              "    'scene': {'show_reprojection_error': True,\n",
              "     'extrinsics_extension': 'png',\n",
              "     'object_coords_3d': [[-2.0, 0.3, 0.0],\n",
              "      [-2.0, 0.0, 0.0],\n",
              "      [-2.0, 0.0, 0.05],\n",
              "      [-2.0, -0.3, 0.0],\n",
              "      [0.0, 0.3, 0.0],\n",
              "      [0.0, 0.0, 0.0],\n",
              "      [0.0, 0.0, 0.05],\n",
              "      [0.0, -0.3, 0.0]]},\n",
              "    'keypoints': {}}}},\n",
              " 'personAssociation': {'likelihood_threshold_association': 0.3,\n",
              "  'single_person': {'reproj_error_threshold_association': 20,\n",
              "   'tracked_keypoint': 'Neck'},\n",
              "  'multi_person': {'reconstruction_error_threshold': 0.1,\n",
              "   'min_affinity': 0.2}},\n",
              " 'triangulation': {'reproj_error_threshold_triangulation': 15,\n",
              "  'likelihood_threshold_triangulation': 0.3,\n",
              "  'min_cameras_for_triangulation': 2,\n",
              "  'interpolation': 'linear',\n",
              "  'interp_if_gap_smaller_than': 10,\n",
              "  'show_interp_indices': True,\n",
              "  'fill_large_gaps_with': 'last_value',\n",
              "  'handle_LR_swap': False,\n",
              "  'undistort_points': False,\n",
              "  'make_c3d': True},\n",
              " 'filtering': {'type': 'butterworth',\n",
              "  'display_figures': True,\n",
              "  'make_c3d': True,\n",
              "  'butterworth': {'order': 4, 'cut_off_frequency': 6},\n",
              "  'kalman': {'trust_ratio': 100, 'smooth': True},\n",
              "  'butterworth_on_speed': {'order': 4, 'cut_off_frequency': 10},\n",
              "  'gaussian': {'sigma_kernel': 2},\n",
              "  'LOESS': {'nb_values_used': 30},\n",
              "  'median': {'kernel_size': 9}},\n",
              " 'markerAugmentation': {'make_c3d': True},\n",
              " 'kinematics': {'use_augmentation': True,\n",
              "  'right_left_symmetry': True,\n",
              "  'remove_individual_scaling_setup': True,\n",
              "  'remove_individual_IK_setup': True,\n",
              "  'fastest_frames_to_remove_percent': 0.1,\n",
              "  'close_to_zero_speed_m': 0.2,\n",
              "  'large_hip_knee_angles': 45,\n",
              "  'trimmed_extrema_percent': 0.5}}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "level"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OKQ8Y3TNq1od",
        "outputId": "42d39478-b97b-4f8d-adf8-80981ceefdf3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config_dict.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2MmFlW2kqwRR",
        "outputId": "b972682b-6d54-4cd0-d560-422718b77672"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['project', 'pose', 'synchronization', 'calibration', 'personAssociation', 'triangulation', 'filtering', 'markerAugmentation', 'kinematics'])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Калибровка камер\n",
        "В конфиге изменим настройки\n",
        "[calibration]\n",
        "calibration_type = 'calculate'"
      ],
      "metadata": {
        "id": "WtHpo4VTv4KN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def imgp_objp_visualizer_clicker(img, imgp=[], objp=[], img_path=''):\n",
        "    '''\n",
        "    Shows image img.\n",
        "    If imgp is given, displays them in green\n",
        "    If objp is given, can be displayed in a 3D plot if 'C' is pressed.\n",
        "    If img_path is given, just uses it to name the window\n",
        "\n",
        "    If 'Y' is pressed, closes all and returns confirmed imgp and (if given) objp\n",
        "    If 'N' is pressed, closes all and returns nothing\n",
        "    If 'C' is pressed, allows clicking imgp by hand. If objp is given:\n",
        "        Displays them in 3D as a helper.\n",
        "        Left click to add a point, right click to remove the last point.\n",
        "        Press 'H' to indicate that one of the objp is not visible on image\n",
        "        Closes all and returns imgp and objp if all points have been clicked\n",
        "    Allows for zooming and panning with middle click\n",
        "\n",
        "    INPUTS:\n",
        "    - img: image opened with openCV\n",
        "    - optional: imgp: detected image points, to be accepted or not. Array of [[2d corner coordinates]]\n",
        "    - optional: objp: array of [3d corner coordinates]\n",
        "    - optional: img_path: path to image\n",
        "\n",
        "    OUTPUTS:\n",
        "    - imgp_confirmed: image points that have been correctly identified. array of [[2d corner coordinates]]\n",
        "    - only if objp!=[]: objp_confirmed: array of [3d corner coordinates]\n",
        "    '''\n",
        "    global old_image_path\n",
        "    old_image_path = img_path\n",
        "\n",
        "    def on_key(event):\n",
        "        '''\n",
        "        Handles key press events:\n",
        "        'Y' to return imgp, 'N' to dismiss image, 'C' to click points by hand.\n",
        "        Left click to add a point, 'H' to indicate it is not visible, right click to remove the last point.\n",
        "        '''\n",
        "\n",
        "        global imgp_confirmed, objp_confirmed, objp_confirmed_notok, scat, ax_3d, fig_3d, events, count\n",
        "\n",
        "        if event.key == 'y':\n",
        "            # If 'y', close all\n",
        "            # If points have been clicked, imgp_confirmed is returned, else imgp\n",
        "            # If objp is given, objp_confirmed is returned in addition\n",
        "            if 'scat' not in globals() or 'imgp_confirmed' not in globals():\n",
        "                imgp_confirmed = imgp\n",
        "                objp_confirmed = objp\n",
        "            else:\n",
        "                imgp_confirmed = np.array([imgp.astype('float32') for imgp in imgp_confirmed])\n",
        "                objp_confirmed = objp_confirmed\n",
        "            # OpenCV needs at leas 4 correspondance points to calibrate\n",
        "            if len(imgp_confirmed) < 6:\n",
        "                objp_confirmed = []\n",
        "                imgp_confirmed = []\n",
        "            # close all, del all global variables except imgp_confirmed and objp_confirmed\n",
        "            plt.close('all')\n",
        "            if len(objp) == 0:\n",
        "                if 'objp_confirmed' in globals():\n",
        "                    del objp_confirmed\n",
        "\n",
        "        if event.key == 'n' or event.key == 'q':\n",
        "            # If 'n', close all and return nothing\n",
        "            plt.close('all')\n",
        "            imgp_confirmed = []\n",
        "            objp_confirmed = []\n",
        "\n",
        "        if event.key == 'c':\n",
        "            # TODO: RIGHT NOW, IF 'C' IS PRESSED ANOTHER TIME, OBJP_CONFIRMED AND IMGP_CONFIRMED ARE RESET TO []\n",
        "            # We should reopen a figure without point on it\n",
        "            img_for_pointing = cv2.imread(old_image_path)\n",
        "            if img_for_pointing is None:\n",
        "                cap = cv2.VideoCapture(old_image_path)\n",
        "                ret, img_for_pointing = cap.read()\n",
        "            img_for_pointing = cv2.cvtColor(img_for_pointing, cv2.COLOR_BGR2RGB)\n",
        "            ax.imshow(img_for_pointing)\n",
        "            # To update the image\n",
        "            plt.draw()\n",
        "\n",
        "            if 'objp_confirmed' in globals():\n",
        "                del objp_confirmed\n",
        "            # If 'c', allows retrieving imgp_confirmed by clicking them on the image\n",
        "            scat = ax.scatter([],[],s=100,marker='+',color='g')\n",
        "            plt.connect('button_press_event', on_click)\n",
        "            # If objp is given, display 3D object points in black\n",
        "            if len(objp) != 0 and not plt.fignum_exists(2):\n",
        "                fig_3d = plt.figure()\n",
        "                fig_3d.tight_layout()\n",
        "                fig_3d.canvas.manager.set_window_title('Object points to be clicked')\n",
        "                ax_3d = fig_3d.add_subplot(projection='3d')\n",
        "                plt.rc('xtick', labelsize=5)\n",
        "                plt.rc('ytick', labelsize=5)\n",
        "                for i, (xs,ys,zs) in enumerate(np.float32(objp)):\n",
        "                    ax_3d.scatter(xs,ys,zs, marker='.', color='k')\n",
        "                    ax_3d.text(xs,ys,zs,  f'{str(i+1)}', size=10, zorder=1, color='k')\n",
        "                set_axes_equal(ax_3d)\n",
        "                ax_3d.set_xlabel('X')\n",
        "                ax_3d.set_ylabel('Y')\n",
        "                ax_3d.set_zlabel('Z')\n",
        "                if np.all(objp[:,2] == 0):\n",
        "                    ax_3d.view_init(elev=-90, azim=0)\n",
        "                fig_3d.show()\n",
        "\n",
        "        if event.key == 'h':\n",
        "            # If 'h', indicates that one of the objp is not visible on image\n",
        "            # Displays it in red on 3D plot\n",
        "            if len(objp) != 0  and 'ax_3d' in globals():\n",
        "                count = [0 if 'count' not in globals() else count+1][0]\n",
        "                if 'events' not in globals():\n",
        "                    # retrieve first objp_confirmed_notok and plot 3D\n",
        "                    events = [event]\n",
        "                    objp_confirmed_notok = objp[count]\n",
        "                    ax_3d.scatter(*objp_confirmed_notok, marker='o', color='r')\n",
        "                    fig_3d.canvas.draw()\n",
        "                elif count == len(objp)-1:\n",
        "                    # if all objp have been clicked or indicated as not visible, close all\n",
        "                    objp_confirmed = np.array([[objp[count]] if 'objp_confirmed' not in globals() else objp_confirmed+[objp[count]]][0])[:-1]\n",
        "                    imgp_confirmed = np.array(np.expand_dims(scat.get_offsets(), axis=1), np.float32)\n",
        "                    plt.close('all')\n",
        "                    for var_to_delete in ['events', 'count', 'scat', 'fig_3d', 'ax_3d', 'objp_confirmed_notok']:\n",
        "                        if var_to_delete in globals():\n",
        "                            del globals()[var_to_delete]\n",
        "                else:\n",
        "                    # retrieve other objp_confirmed_notok and plot 3D\n",
        "                    events.append(event)\n",
        "                    objp_confirmed_notok = objp[count]\n",
        "                    ax_3d.scatter(*objp_confirmed_notok, marker='o', color='r')\n",
        "                    fig_3d.canvas.draw()\n",
        "            else:\n",
        "                pass\n",
        "\n",
        "\n",
        "    def on_click(event):\n",
        "        '''\n",
        "        Detect click position on image\n",
        "        If right click, last point is removed\n",
        "        '''\n",
        "\n",
        "        global imgp_confirmed, objp_confirmed, objp_confirmed_notok, scat, ax_3d, fig_3d, events, count, xydata\n",
        "\n",
        "        # Left click: Add clicked point to imgp_confirmed\n",
        "        # Display it on image and on 3D plot\n",
        "        if event.button == 1:\n",
        "            # To remember the event to cancel after right click\n",
        "            if 'events' in globals():\n",
        "                events.append(event)\n",
        "            else:\n",
        "                events = [event]\n",
        "\n",
        "            # Add clicked point to image\n",
        "            xydata = scat.get_offsets()\n",
        "            new_xydata = np.concatenate((xydata,[[event.xdata,event.ydata]]))\n",
        "            scat.set_offsets(new_xydata)\n",
        "            imgp_confirmed = np.expand_dims(scat.get_offsets(), axis=1)\n",
        "            plt.draw()\n",
        "\n",
        "            # Add clicked point to 3D object points if given\n",
        "            if len(objp) != 0:\n",
        "                count = [0 if 'count' not in globals() else count+1][0]\n",
        "                if count==0:\n",
        "                    # retrieve objp_confirmed and plot 3D\n",
        "                    objp_confirmed = [objp[count]]\n",
        "                    ax_3d.scatter(*objp[count], marker='o', color='g')\n",
        "                    fig_3d.canvas.draw()\n",
        "                elif count == len(objp)-1:\n",
        "                    # close all\n",
        "                    plt.close('all')\n",
        "                    # retrieve objp_confirmed\n",
        "                    objp_confirmed = np.array([[objp[count]] if 'objp_confirmed' not in globals() else objp_confirmed+[objp[count]]][0])\n",
        "                    imgp_confirmed = np.array(imgp_confirmed, np.float32)\n",
        "                    # delete all\n",
        "                    for var_to_delete in ['events', 'count', 'scat', 'scat_3d', 'fig_3d', 'ax_3d', 'objp_confirmed_notok']:\n",
        "                        if var_to_delete in globals():\n",
        "                            del globals()[var_to_delete]\n",
        "                else:\n",
        "                    # retrieve objp_confirmed and plot 3D\n",
        "                    objp_confirmed = [[objp[count]] if 'objp_confirmed' not in globals() else objp_confirmed+[objp[count]]][0]\n",
        "                    ax_3d.scatter(*objp[count], marker='o', color='g')\n",
        "                    fig_3d.canvas.draw()\n",
        "\n",
        "\n",
        "        # Right click:\n",
        "        # If last event was left click, remove last point and if objp given, from objp_confirmed\n",
        "        # If last event was 'H' and objp given, remove last point from objp_confirmed_notok\n",
        "        elif event.button == 3: # right click\n",
        "            if 'events' in globals():\n",
        "                # If last event was left click:\n",
        "                if 'button' in dir(events[-1]):\n",
        "                    if events[-1].button == 1:\n",
        "                        # Remove lastpoint from image\n",
        "                        new_xydata = scat.get_offsets()[:-1]\n",
        "                        scat.set_offsets(new_xydata)\n",
        "                        plt.draw()\n",
        "                        # Remove last point from imgp_confirmed\n",
        "                        imgp_confirmed = imgp_confirmed[:-1]\n",
        "                        if len(objp) != 0:\n",
        "                            if count >= 0:\n",
        "                                count -= 1\n",
        "                            # Remove last point from objp_confirmed\n",
        "                            objp_confirmed = objp_confirmed[:-1]\n",
        "                            # remove from plot\n",
        "                            if len(ax_3d.collections) > len(objp):\n",
        "                                ax_3d.collections[-1].remove()\n",
        "                                fig_3d.canvas.draw()\n",
        "\n",
        "                # If last event was 'h' key\n",
        "                elif events[-1].key == 'h':\n",
        "                    if len(objp) != 0:\n",
        "                        if count >= 1: count -= 1\n",
        "                        # Remove last point from objp_confirmed_notok\n",
        "                        objp_confirmed_notok = objp_confirmed_notok[:-1]\n",
        "                        # remove from plot\n",
        "                        if len(ax_3d.collections) > len(objp):\n",
        "                            ax_3d.collections[-1].remove()\n",
        "                            fig_3d.canvas.draw()\n",
        "\n",
        "\n",
        "    def set_axes_equal(ax):\n",
        "        '''\n",
        "        Make axes of 3D plot have equal scale so that spheres appear as spheres,\n",
        "        cubes as cubes, etc.\n",
        "        From https://stackoverflow.com/questions/13685386/how-to-set-the-equal-aspect-ratio-for-all-axes-x-y-z\n",
        "\n",
        "        Input\n",
        "        ax: a matplotlib axis, e.g., as output from plt.gca().\n",
        "        '''\n",
        "\n",
        "        x_limits = ax.get_xlim3d()\n",
        "        y_limits = ax.get_ylim3d()\n",
        "        z_limits = ax.get_zlim3d()\n",
        "\n",
        "        x_range = abs(x_limits[1] - x_limits[0])\n",
        "        x_middle = np.mean(x_limits)\n",
        "        y_range = abs(y_limits[1] - y_limits[0])\n",
        "        y_middle = np.mean(y_limits)\n",
        "        z_range = abs(z_limits[1] - z_limits[0])\n",
        "        z_middle = np.mean(z_limits)\n",
        "\n",
        "        # The plot bounding box is a sphere in the sense of the infinity\n",
        "        # norm, hence I call half the max range the plot radius.\n",
        "        plot_radius = 0.5*max([x_range, y_range, z_range])\n",
        "\n",
        "        ax.set_xlim3d([x_middle - plot_radius, x_middle + plot_radius])\n",
        "        ax.set_ylim3d([y_middle - plot_radius, y_middle + plot_radius])\n",
        "        ax.set_zlim3d([z_middle - plot_radius, z_middle + plot_radius])\n",
        "\n",
        "    # Write instructions\n",
        "    cv2.putText(img, 'Type \"Y\" to accept point detection.', (20, 20), cv2.FONT_HERSHEY_SIMPLEX, .7, (255,255,255), 7, lineType = cv2.LINE_AA)\n",
        "    cv2.putText(img, 'Type \"Y\" to accept point detection.', (20, 20), cv2.FONT_HERSHEY_SIMPLEX, .7, (0,0,0), 2, lineType = cv2.LINE_AA)\n",
        "    cv2.putText(img, 'If points are wrongfully (or not) detected:', (20, 43), cv2.FONT_HERSHEY_SIMPLEX, .7, (255,255,255), 7, lineType = cv2.LINE_AA)\n",
        "    cv2.putText(img, 'If points are wrongfully (or not) detected:', (20, 43), cv2.FONT_HERSHEY_SIMPLEX, .7, (0,0,0), 2, lineType = cv2.LINE_AA)\n",
        "    cv2.putText(img, '- type \"N\" to dismiss this image,', (20, 66), cv2.FONT_HERSHEY_SIMPLEX, .7, (255,255,255), 7, lineType = cv2.LINE_AA)\n",
        "    cv2.putText(img, '- type \"N\" to dismiss this image,', (20, 66), cv2.FONT_HERSHEY_SIMPLEX, .7, (0,0,0), 2, lineType = cv2.LINE_AA)\n",
        "    cv2.putText(img, '- type \"C\" to click points by hand (beware of their order).', (20, 89), cv2.FONT_HERSHEY_SIMPLEX, .7, (255,255,255), 7, lineType = cv2.LINE_AA)\n",
        "    cv2.putText(img, '- type \"C\" to click points by hand (beware of their order).', (20, 89), cv2.FONT_HERSHEY_SIMPLEX, .7, (0,0,0), 2, lineType = cv2.LINE_AA)\n",
        "    cv2.putText(img, '   left click to add a point, right click to remove it, \"H\" to indicate it is not visible. ', (20, 112), cv2.FONT_HERSHEY_SIMPLEX, .7, (255,255,255), 7, lineType = cv2.LINE_AA)\n",
        "    cv2.putText(img, '   left click to add a point, right click to remove it, \"H\" to indicate it is not visible. ', (20, 112), cv2.FONT_HERSHEY_SIMPLEX, .7, (0,0,0), 2, lineType = cv2.LINE_AA)\n",
        "    cv2.putText(img, '   Confirm with \"Y\", cancel with \"N\".', (20, 135), cv2.FONT_HERSHEY_SIMPLEX, .7, (255,255,255), 7, lineType = cv2.LINE_AA)\n",
        "    cv2.putText(img, '   Confirm with \"Y\", cancel with \"N\".', (20, 135), cv2.FONT_HERSHEY_SIMPLEX, .7, (0,0,0), 2, lineType = cv2.LINE_AA)\n",
        "    cv2.putText(img, 'Use mouse wheel to zoom in and out and to pan', (20, 158), cv2.FONT_HERSHEY_SIMPLEX, .7, (255,255,255), 7, lineType = cv2.LINE_AA)\n",
        "    cv2.putText(img, 'Use mouse wheel to zoom in and out and to pan', (20, 158), cv2.FONT_HERSHEY_SIMPLEX, .7, (0,0,0), 2, lineType = cv2.LINE_AA)\n",
        "\n",
        "    # Put image in a matplotlib figure for more controls\n",
        "    plt.rcParams['toolbar'] = 'None'\n",
        "    fig, ax = plt.subplots()\n",
        "    fig = plt.gcf()\n",
        "    fig.canvas.manager.set_window_title(os.path.basename(img_path))\n",
        "    ax.axis(\"off\")\n",
        "    for corner in imgp:\n",
        "        x, y = corner.ravel()\n",
        "        cv2.drawMarker(img, (int(x),int(y)), (128,128,128), cv2.MARKER_CROSS, 10, 2)\n",
        "    ax.imshow(img)\n",
        "\n",
        "    #Закоментируем\n",
        "    #figManager = plt.get_current_fig_manager()\n",
        "    #figManager.window.showMaximized()\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # Allow for zoom and pan in image\n",
        "    zoom_factory(ax)\n",
        "    ph = panhandler(fig, button=2)\n",
        "\n",
        "    # Handles key presses to Accept, dismiss, or click points by hand\n",
        "    cid = fig.canvas.mpl_connect('key_press_event', on_key)\n",
        "\n",
        "    plt.draw()\n",
        "    plt.show(block=True)\n",
        "    with warnings.catch_warnings():\n",
        "        warnings.simplefilter(\"ignore\")\n",
        "        plt.rcParams['toolbar'] = 'toolmanager'\n",
        "\n",
        "    for var_to_delete in ['events', 'count', 'scat', 'fig_3d', 'ax_3d', 'objp_confirmed_notok']:\n",
        "        if var_to_delete in globals():\n",
        "            del globals()[var_to_delete]\n",
        "\n",
        "    if 'imgp_confirmed' in globals() and 'objp_confirmed' in globals():\n",
        "        return imgp_confirmed, objp_confirmed\n",
        "    elif 'imgp_confirmed' in globals() and not 'objp_confirmed' in globals():\n",
        "        return imgp_confirmed\n",
        "    else:\n",
        "        return"
      ],
      "metadata": {
        "id": "aFq_ENhz0ilL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def findCorners(img_path, corner_nb, objp=[], show=True):\n",
        "    '''\n",
        "    Найти углы на фотографии шахматной доски.\n",
        "    Нажмите 'Y', чтобы подтвердить обнаружение, 'N', чтобы отклонить это изображение, 'C', чтобы щелкнуть точки вручную.\n",
        "    Левый клик для добавления точки, правый клик для удаления последней точки.\n",
        "    Используйте колесо мыши для увеличения и уменьшения масштаба, а также для панорамирования.\n",
        "\n",
        "    Убедитесь, что:\n",
        "    - шахматная доска окружена белой рамкой\n",
        "    - количество рядов не равно количеству линий, и ряд четный, если линии нечетные (или наоборот)\n",
        "    - она плоская и без отражений\n",
        "    - corner_nb соответствует _внутренним_ углам\n",
        "\n",
        "    ВХОДНЫЕ ДАННЫЕ:\n",
        "    - img_path: путь к изображению (или видео)\n",
        "    - corner_nb: [H, W] внутренние углы на шахматной доске: список из двух целых чисел [4,7]\n",
        "    - необязательный: show: выберите, показывать ли обнаруженные углы\n",
        "    - необязательный: objp: массив [3d координаты углов]\n",
        "\n",
        "    ВЫХОДНЫЕ ДАННЫЕ:\n",
        "    - imgp_confirmed: массив [[2d координаты углов]]\n",
        "    - только если objp!=[]: objp_confirmed: массив [3d координаты углов]\n",
        "    '''\n",
        "\n",
        "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001) # остановить уточнение после 30 итераций или если ошибка меньше 0.001 пикселя\n",
        "\n",
        "    img = cv2.imread(img_path)  # Чтение изображения из указанного пути\n",
        "    if img is None:  # Если изображение не найдено, попытка прочитать из видео\n",
        "        cap = cv2.VideoCapture(img_path)\n",
        "        ret, img = cap.read()\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  # Преобразование изображения в оттенки серого\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Преобразование изображения в формат RGB\n",
        "\n",
        "    # Поиск углов\n",
        "    ret, corners = cv2.findChessboardCorners(gray, corner_nb, None)\n",
        "    # Если углы найдены, уточнить их положение\n",
        "    if ret == True:\n",
        "        imgp = cv2.cornerSubPix(gray, corners, (11,11), (-1,-1), criteria)  # Уточнение углов\n",
        "        logging.info(f'{os.path.basename(img_path)}: Углы найдены.')\n",
        "\n",
        "        if show:\n",
        "            # Отрисовка углов на изображении\n",
        "            cv2.drawChessboardCorners(img, corner_nb, imgp, ret)\n",
        "            # Добавление индекса угла\n",
        "            for i, corner in enumerate(imgp):\n",
        "                if i in [0, corner_nb[0]-1, corner_nb[0]*(corner_nb[1]-1), corner_nb[0]*corner_nb[1] -1]:\n",
        "                    x, y = corner.ravel()\n",
        "                    cv2.putText(img, str(i+1), (int(x)-5, int(y)-5), cv2.FONT_HERSHEY_SIMPLEX, .8, (255, 255, 255), 7)\n",
        "                    cv2.putText(img, str(i+1), (int(x)-5, int(y)-5), cv2.FONT_HERSHEY_SIMPLEX, .8, (0,0,0), 2)\n",
        "\n",
        "            # Визуализатор и обработчик событий нажатия клавиш\n",
        "            for var_to_delete in ['imgp_confirmed', 'objp_confirmed']:\n",
        "                if var_to_delete in globals():\n",
        "                    del globals()[var_to_delete]\n",
        "            imgp_objp_confirmed = imgp_objp_visualizer_clicker(img, imgp=imgp, objp=objp, img_path=img_path)\n",
        "        else:\n",
        "            imgp_objp_confirmed = imgp  # Если не показывать, просто возвращаем уточненные углы\n",
        "\n",
        "    # Если углы не найдены, отклоняем или щелкаем точки вручную\n",
        "    else:\n",
        "        if show:\n",
        "            # Визуализатор и обработчик событий нажатия клавиш\n",
        "            logging.info(f'{os.path.basename(img_path)}: Углы не найдены: пожалуйста, пометьте их вручную.')\n",
        "            imgp_objp_confirmed = imgp_objp_visualizer_clicker(img, imgp=[], objp=objp, img_path=img_path)\n",
        "        else:\n",
        "            logging.info(f'{os.path.basename(img_path)}: Углы не найдены. Чтобы пометить их вручную, установите \"show_detection_intrinsics\" в true в файле Config.toml.')\n",
        "            imgp_objp_confirmed = []\n",
        "\n",
        "    return imgp_objp_confirmed  # Возвращаем подтвержденные углы"
      ],
      "metadata": {
        "id": "BACI7PVGztC9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calibrate_intrinsics(calib_dir, intrinsics_config_dict):\n",
        "    '''\n",
        "    Рассчитать внутренние параметры\n",
        "    на основе изображений или видео с шахматной доской.\n",
        "    Извлечь кадры, затем обнаружить углы, затем выполнить калибровку.\n",
        "\n",
        "    ВХОДНЫЕ ДАННЫЕ:\n",
        "    - calib_dir: директория, содержащая папки с внутренними и внешними параметрами, каждая из которых заполнена директориями камер\n",
        "    - intrinsics_config_dict: словарь параметров внутренней калибровки (overwrite_intrinsics, show_detection_intrinsics, intrinsics_extension, extract_every_N_sec, intrinsics_corners_nb, intrinsics_square_size, intrinsics_marker_size, intrinsics_aruco_dict)\n",
        "\n",
        "    ВЫХОДНЫЕ ДАННЫЕ:\n",
        "    - D: искажения: список массивов с плавающей точкой\n",
        "    - K: внутренние параметры: список 3x3 массивов с плавающей точкой\n",
        "    '''\n",
        "\n",
        "    try:\n",
        "        # Получаем список директорий камер из папки 'intrinsics'\n",
        "        intrinsics_cam_listdirs_names = next(os.walk(os.path.join(calib_dir, 'intrinsics')))[1]\n",
        "    except StopIteration:\n",
        "        logging.exception(f'Ошибка: Папка {os.path.join(calib_dir, \"intrinsics\")} не найдена.')\n",
        "        raise Exception(f'Ошибка: Папка {os.path.join(calib_dir, \"intrinsics\")} не найдена.')\n",
        "\n",
        "    # Извлекаем параметры из словаря конфигурации\n",
        "    intrinsics_extension = intrinsics_config_dict.get('intrinsics_extension')\n",
        "    extract_every_N_sec = intrinsics_config_dict.get('extract_every_N_sec')\n",
        "    overwrite_extraction = False\n",
        "    show_detection_intrinsics = intrinsics_config_dict.get('show_detection_intrinsics')\n",
        "    intrinsics_corners_nb = intrinsics_config_dict.get('intrinsics_corners_nb')\n",
        "    intrinsics_square_size = intrinsics_config_dict.get('intrinsics_square_size') / 1000  # перевод в метры\n",
        "    ret, C, S, D, K, R, T = [], [], [], [], [], [], []\n",
        "\n",
        "    for i, cam in enumerate(intrinsics_cam_listdirs_names):\n",
        "        # Подготовка объектных точек\n",
        "        objp = np.zeros((intrinsics_corners_nb[0] * intrinsics_corners_nb[1], 3), np.float32)\n",
        "        objp[:, :2] = np.mgrid[0:intrinsics_corners_nb[0], 0:intrinsics_corners_nb[1]].T.reshape(-1, 2)\n",
        "        objp[:, :2] = objp[:, 0:2] * intrinsics_square_size\n",
        "        objpoints = []  # 3D точки в мировом пространстве\n",
        "        imgpoints = []  # 2D точки в плоскости изображения\n",
        "\n",
        "        logging.info(f'\\nКамера {cam}:')\n",
        "        img_vid_files = glob.glob(os.path.join(calib_dir, 'intrinsics', cam, f'*.{intrinsics_extension}'))\n",
        "        if len(img_vid_files) == 0:\n",
        "            logging.exception(f'Папка {os.path.join(calib_dir, \"intrinsics\", cam)} не существует или не содержит файлов с расширением .{intrinsics_extension}.')\n",
        "            raise ValueError(f'Папка {os.path.join(calib_dir, \"intrinsics\", cam)} не существует или не содержит файлов с расширением .{intrinsics_extension}.')\n",
        "\n",
        "        # Сортировка файлов по числовым значениям в имени\n",
        "        img_vid_files = sorted(img_vid_files, key=lambda c: [int(n) for n in re.findall(r'\\d+', c)])\n",
        "\n",
        "        # Извлечение кадров из видео, если это видео\n",
        "        try:\n",
        "            cap = cv2.VideoCapture(img_vid_files[0])\n",
        "            cap.read()\n",
        "            if cap.read()[0] == False:\n",
        "                raise\n",
        "            extract_frames(img_vid_files[0], extract_every_N_sec, overwrite_extraction)\n",
        "            img_vid_files = glob.glob(os.path.join(calib_dir, 'intrinsics', cam, f'*.png'))\n",
        "            img_vid_files = sorted(img_vid_files, key=lambda c: [int(n) for n in re.findall(r'\\d+', c)])\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "        # Поиск углов\n",
        "        for img_path in img_vid_files:\n",
        "            if show_detection_intrinsics == True:\n",
        "                imgp_confirmed, objp_confirmed = findCorners(img_path, intrinsics_corners_nb, objp=objp, show=show_detection_intrinsics)\n",
        "                if isinstance(imgp_confirmed, np.ndarray):\n",
        "                    imgpoints.append(imgp_confirmed)\n",
        "                    objpoints.append(objp_confirmed)\n",
        "            else:\n",
        "                imgp_confirmed = findCorners(img_path, intrinsics_corners_nb, objp=objp, show=show_detection_intrinsics)\n",
        "                if isinstance(imgp_confirmed, np.ndarray):\n",
        "                    imgpoints.append(imgp_confirmed)\n",
        "                    objpoints.append(objp)\n",
        "\n",
        "        if len(imgpoints) < 10:\n",
        "            logging.info(f'Углы были обнаружены только на {len(imgpoints)} изображениях для камеры {cam}. Калибровка внутренних параметров может быть неточной при наличии менее 10 хороших изображений доски.')\n",
        "\n",
        "        # Расчет внутренних параметров\n",
        "        img = cv2.imread(str(img_path))\n",
        "        objpoints = np.array(objpoints)\n",
        "        ret_cam, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, img.shape[1::-1],\n",
        "                                    None, None, flags=(cv2.CALIB_FIX_K3))  # + cv2.CALIB_FIX_PRINCIPAL_POINT))\n",
        "        h, w = [np.float32(i) for i in img.shape[:-1]]\n",
        "        ret.append(ret_cam)\n",
        "        C.append(cam)\n",
        "        S.append([w, h])\n",
        "        D.append(dist[0])\n",
        "        K.append(mtx)\n",
        "        R.append([0.0, 0.0, 0.0])\n",
        "        T.append([0.0, 0.0, 0.0])\n",
        "\n",
        "        logging.info(f'Ошибка внутренних параметров: {np.around(ret_cam, decimals=3)} пикселей для каждой камеры.')\n",
        "\n",
        "    return ret, C, S, D, K, R, T"
      ],
      "metadata": {
        "id": "-Ql9XViizHgf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title calibrate_extrinsics\n",
        "def calibrate_extrinsics(calib_dir, extrinsics_config_dict, C, S, K, D):\n",
        "    '''\n",
        "    Калибрует экстраординарные параметры\n",
        "    из изображения или первого кадра видео\n",
        "    шахматной доски или измеренных объектов на сцене\n",
        "\n",
        "    ВХОДНЫЕ ДАННЫЕ:\n",
        "    - calib_dir: директория, содержащая папки с внутренними и экстраординарными параметрами, каждая из которых заполнена директориями камер\n",
        "    - extrinsics_config_dict: словарь параметров экстраординарных параметров (extrinsics_method, calculate_extrinsics, show_detection_extrinsics, extrinsics_extension, extrinsics_corners_nb, extrinsics_square_size, extrinsics_marker_size, extrinsics_aruco_dict, object_coords_3d)\n",
        "\n",
        "    ВЫХОДНЫЕ ДАННЫЕ:\n",
        "    - R: экстраординарная ротация: список массивов с плавающей запятой (Родригес)\n",
        "    - T: экстраординарный перевод: список массивов с плавающей запятой\n",
        "    '''\n",
        "\n",
        "    try:\n",
        "        # Получаем список директорий камер из папки 'extrinsics'\n",
        "        extrinsics_cam_listdirs_names = next(os.walk(os.path.join(calib_dir, 'extrinsics')))[1]\n",
        "    except StopIteration:\n",
        "        logging.exception(f'Ошибка: Папка {os.path.join(calib_dir, \"extrinsics\")} не найдена.')\n",
        "        raise Exception(f'Ошибка: Папка {os.path.join(calib_dir, \"extrinsics\")} не найдена.')\n",
        "\n",
        "    extrinsics_method = extrinsics_config_dict.get('extrinsics_method')\n",
        "    ret, R, T = [], [], []\n",
        "\n",
        "    if extrinsics_method in {'board', 'scene'}:\n",
        "\n",
        "        # Определяем 3D координаты объектов\n",
        "        if extrinsics_method == 'board':\n",
        "            extrinsics_corners_nb = extrinsics_config_dict.get('board').get('extrinsics_corners_nb')\n",
        "            extrinsics_square_size = extrinsics_config_dict.get('board').get('extrinsics_square_size') / 1000 # переводим в метры\n",
        "            object_coords_3d = np.zeros((extrinsics_corners_nb[0] * extrinsics_corners_nb[1], 3), np.float32)\n",
        "            object_coords_3d[:, :2] = np.mgrid[0:extrinsics_corners_nb[0], 0:extrinsics_corners_nb[1]].T.reshape(-1, 2)\n",
        "            object_coords_3d[:, :2] = object_coords_3d[:, 0:2] * extrinsics_square_size\n",
        "        elif extrinsics_method == 'scene':\n",
        "            object_coords_3d = np.array(extrinsics_config_dict.get('scene').get('object_coords_3d'), np.float32)\n",
        "\n",
        "        # Сохраняем 3D координаты объектов в формате trc\n",
        "        calib_output_path = os.path.join(calib_dir, f'Object_points.trc')\n",
        "        trc_write(object_coords_3d, calib_output_path)\n",
        "\n",
        "        for i, cam in enumerate(extrinsics_cam_listdirs_names):\n",
        "            logging.info(f'\\nКамера {cam}:')\n",
        "\n",
        "            # Читаем изображения или видео\n",
        "            extrinsics_extension = [extrinsics_config_dict.get('board').get('extrinsics_extension') if extrinsics_method == 'board'\n",
        "                                    else extrinsics_config_dict.get('scene').get('extrinsics_extension')][0]\n",
        "            show_reprojection_error = [extrinsics_config_dict.get('board').get('show_reprojection_error') if extrinsics_method == 'board'\n",
        "                                    else extrinsics_config_dict.get('scene').get('show_reprojection_error')][0]\n",
        "            img_vid_files = glob.glob(os.path.join(calib_dir, 'extrinsics', cam, f'*.{extrinsics_extension}'))\n",
        "            if len(img_vid_files) == 0:\n",
        "                logging.exception(f'Папка {os.path.join(calib_dir, \"extrinsics\", cam)} не существует или не содержит файлов с расширением .{extrinsics_extension}.')\n",
        "                raise ValueError(f'Папка {os.path.join(calib_dir, \"extrinsics\", cam)} не существует или не содержит файлов с расширением .{extrinsics_extension}.')\n",
        "            img_vid_files = sorted(img_vid_files, key=lambda c: [int(n) for n in re.findall(r'\\d+', c)]) # сортируем пути с числами\n",
        "\n",
        "            # Извлекаем кадры из изображения или видео, если imread равно None\n",
        "            img = cv2.imread(img_vid_files[0])\n",
        "            if img is None:\n",
        "                cap = cv2.VideoCapture(img_vid_files[0])\n",
        "                res, img = cap.read()\n",
        "                if res == False:\n",
        "                    raise\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "            # Находим углы или помечаем вручную\n",
        "            if extrinsics_method == 'board':\n",
        "                imgp = findCorners(img_vid_files[0], extrinsics_corners_nb, objp=object_coords_3d, show=show_reprojection_error)\n",
        "                objp = object_coords_3d\n",
        "                if len(imgp) == 0:\n",
        "                    logging.exception('Углы не найдены. Установите \"show_detection_extrinsics\" в true, чтобы щелкнуть углы вручную, или измените extrinsic_board_type на \"scene\"')\n",
        "                    raise ValueError('Углы не найдены. Установите \"show_detection_extrinsics\" в true, чтобы щелкнуть углы вручную, или измените extrinsic_board_type на \"scene\"')\n",
        "\n",
        "            elif extrinsics_method == 'scene':\n",
        "                imgp, objp = imgp_objp_visualizer_clicker(img, imgp=[], objp=object_coords_3d, img_path=img_vid_files[0])\n",
        "                if len(imgp) == 0:\n",
        "                    logging.exception('Не нажаты точки (или меньше 6). Нажмите \\'C\\', когда изображение отображается, а затем щелкните по точкам изображения, соответствующим \\'object_coords_3d\\', которые вы измерили и записали в файл Config.toml.')\n",
        "                    raise ValueError('Не нажаты точки (или меньше 6). Нажмите \\'C\\', когда изображение отображается, а затем щелкните по точкам изображения, соответствующим \\'object_coords_3d\\', которые вы измерили и записали в файл Config.toml.')\n",
        "                if len(objp) < 10:\n",
        "                    logging.info(f'Только {len(objp)} контрольных точек для камеры {cam}. Калибровка экстраординарных параметров может быть неточной с менее чем 10 контрольными точками, распределенными по захваченному объему как можно шире.')\n",
        "\n",
        "            elif extrinsics_method == 'keypoints':\n",
        "                logging.info('Калибровка на основе ключевых точек пока не доступна.')\n",
        "\n",
        "            # Вычисляем экстраординарные параметры\n",
        "            mtx, dist = np.array(K[i]), np.array(D[i])\n",
        "            _, r, t = cv2.solvePnP(np.array(objp)*1000, imgp, mtx, dist)\n",
        "            r, t = r.flatten(), t.flatten()\n",
        "            t /= 1000\n",
        "\n",
        "            # Проекция 3D точек объектов на плоскость изображения\n",
        "            proj_obj = np.squeeze(cv2.projectPoints(objp, r, t, mtx, dist)[0])\n",
        "\n",
        "            # Проверка результатов калибровки\n",
        "            if show_reprojection_error:\n",
        "                # Снова открываем изображение, иначе два набора текста накладываются друг на друга\n",
        "                img = cv2.imread(img_vid_files[0])\n",
        "                if img is None:\n",
        "                    cap = cv2.VideoCapture(img_vid_files[0])\n",
        "                    res, img = cap.read()\n",
        "                    if res == False:\n",
        "                        raise\n",
        "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "                for o in proj_obj:\n",
        "                    cv2.circle(img, (int(o[0]), int(o[1])), 8, (0,0,255), -1)\n",
        "                for i in imgp:\n",
        "                    cv2.drawMarker(img, (int(i[0][0]), int(i[0][1])), (0,255,0), cv2.MARKER_CROSS, 15, 2)\n",
        "                cv2.putText(img, 'Проверьте результаты калибровки, затем закройте окно.', (20, 20), cv2.FONT_HERSHEY_SIMPLEX, .7, (255,255,255), 7, lineType = cv2.LINE_AA)\n",
        "                cv2.putText(img, 'Проверьте результаты калибровки, затем закройте окно.', (20, 20), cv2.FONT_HERSHEY_SIMPLEX, .7, (0,0,0), 2, lineType = cv2.LINE_AA)\n",
        "                cv2.drawMarker(img, (20,40), (0,255,0), cv2.MARKER_CROSS, 15, 2)\n",
        "                cv2.putText(img, '    Нажатые точки', (20, 40), cv2.FONT_HERSHEY_SIMPLEX, .7, (255,255,255), 7, lineType = cv2.LINE_AA)\n",
        "                cv2.putText(img, '    Нажатые точки', (20, 40), cv2.FONT_HERSHEY_SIMPLEX, .7, (0,0,0), 2, lineType = cv2.LINE_AA)\n",
        "                cv2.circle(img, (20,60), 8, (0,0,255), -1)\n",
        "                cv2.putText(img, '    Проецируемые точки объектов', (20, 60), cv2.FONT_HERSHEY_SIMPLEX, .7, (255,255,255), 7, lineType = cv2.LINE_AA)\n",
        "                cv2.putText(img, '    Проецируемые точки объектов', (20, 60), cv2.FONT_HERSHEY_SIMPLEX, .7, (0,0,0), 2, lineType = cv2.LINE_AA)\n",
        "                im_pil = Image.fromarray(img)\n",
        "                im_pil.show(title = os.path.basename(img_vid_files[0]))\n",
        "\n",
        "            # Вычисляем ошибку проекции\n",
        "            imgp_to_objreproj_dist = [euclidean_distance(proj_obj[n], imgp[n]) for n in range(len(proj_obj))]\n",
        "            rms_px = np.sqrt(np.sum([d**2 for d in imgp_to_objreproj_dist]))\n",
        "            ret.append(rms_px)\n",
        "            R.append(r)\n",
        "            T.append(t)\n",
        "\n",
        "    elif extrinsics_method == 'keypoints':\n",
        "        raise NotImplementedError('Это еще не интегрировано.')\n",
        "\n",
        "    else:\n",
        "        raise ValueError('Неверное значение для extrinsics_method')\n",
        "\n",
        "    return ret, C, S, D, K, R, T"
      ],
      "metadata": {
        "id": "QhLmvloj0A58"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calib_calc_fun(calib_dir, intrinsics_config_dict, extrinsics_config_dict):\n",
        "    '''\n",
        "    Calibrates intrinsic and extrinsic parameters\n",
        "    from images or videos of a checkerboard\n",
        "    or retrieve them from a file\n",
        "\n",
        "    INPUTS:\n",
        "    - calib_dir: directory containing intrinsic and extrinsic folders, each populated with camera directories\n",
        "    - intrinsics_config_dict: dictionary of intrinsics parameters (overwrite_intrinsics, show_detection_intrinsics, intrinsics_extension, extract_every_N_sec, intrinsics_corners_nb, intrinsics_square_size, intrinsics_marker_size, intrinsics_aruco_dict)\n",
        "    - extrinsics_config_dict: dictionary of extrinsics parameters (calculate_extrinsics, show_detection_extrinsics, extrinsics_extension, extrinsics_corners_nb, extrinsics_square_size, extrinsics_marker_size, extrinsics_aruco_dict, object_coords_3d)\n",
        "\n",
        "    OUTPUTS:\n",
        "    - ret: residual reprojection error in _px_: list of floats\n",
        "    - C: camera name: list of strings\n",
        "    - S: image size: list of list of floats\n",
        "    - D: distorsion: list of arrays of floats\n",
        "    - K: intrinsic parameters: list of 3x3 arrays of floats\n",
        "    - R: extrinsic rotation: list of arrays of floats (Rodrigues)\n",
        "    - T: extrinsic translation: list of arrays of floats\n",
        "    '''\n",
        "\n",
        "    overwrite_intrinsics = intrinsics_config_dict.get('overwrite_intrinsics')\n",
        "    calculate_extrinsics = extrinsics_config_dict.get('calculate_extrinsics')\n",
        "\n",
        "    # retrieve intrinsics if calib_file found and if overwrite_intrinsics=False\n",
        "    try:\n",
        "        calib_file = glob.glob(os.path.join(calib_dir, f'Calib*.toml'))[0]\n",
        "    except:\n",
        "        pass\n",
        "    if not overwrite_intrinsics and 'calib_file' in locals():\n",
        "        logging.info(f'\\nPreexisting calibration file found: \\'{calib_file}\\'.')\n",
        "        logging.info(f'\\nRetrieving intrinsic parameters from file. Set \"overwrite_intrinsics\" to true in Config.toml to recalculate them.')\n",
        "        calib_file = glob.glob(os.path.join(calib_dir, f'Calib*.toml'))[0]\n",
        "        calib_data = toml.load(calib_file)\n",
        "\n",
        "        ret, C, S, D, K, R, T = [], [], [], [], [], [], []\n",
        "        for cam in calib_data:\n",
        "            if cam != 'metadata':\n",
        "                ret += [0.0]\n",
        "                C += [calib_data[cam]['name']]\n",
        "                S += [calib_data[cam]['size']]\n",
        "                K += [np.array(calib_data[cam]['matrix'])]\n",
        "                D += [calib_data[cam]['distortions']]\n",
        "                R += [[0.0, 0.0, 0.0]]\n",
        "                T += [[0.0, 0.0, 0.0]]\n",
        "        nb_cams_intrinsics = len(C)\n",
        "\n",
        "    # calculate intrinsics otherwise\n",
        "    else:\n",
        "        logging.info(f'\\nCalculating intrinsic parameters...')\n",
        "        ret, C, S, D, K, R, T = calibrate_intrinsics(calib_dir, intrinsics_config_dict)\n",
        "        nb_cams_intrinsics = len(C)\n",
        "\n",
        "    # calculate extrinsics\n",
        "    if calculate_extrinsics:\n",
        "        logging.info(f'\\nCalculating extrinsic parameters...')\n",
        "\n",
        "        # check that the number of cameras is consistent\n",
        "        nb_cams_extrinsics = len(next(os.walk(os.path.join(calib_dir, 'extrinsics')))[1])\n",
        "        if nb_cams_intrinsics != nb_cams_extrinsics:\n",
        "            raise Exception(f'Error: The number of cameras is not consistent:\\\n",
        "                    Found {nb_cams_intrinsics} cameras based on the number of intrinsic folders or on calibration file data,\\\n",
        "                    and {nb_cams_extrinsics} cameras based on the number of extrinsic folders.')\n",
        "        ret, C, S, D, K, R, T = calibrate_extrinsics(calib_dir, extrinsics_config_dict, C, S, K, D)\n",
        "    else:\n",
        "        logging.info(f'\\nExtrinsic parameters won\\'t be calculated. Set \"calculate_extrinsics\" to true in Config.toml to calculate them.')\n",
        "\n",
        "    return ret, C, S, D, K, R, T"
      ],
      "metadata": {
        "id": "y5-M6Rnqxr8o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calibrate_cams_all(config_dict):\n",
        "    '''\n",
        "    Либо конвертирует существующий файл калибровки,\n",
        "    либо вычисляет калибровку с нуля (с доски или из точек).\n",
        "    Сохраняет калибровку в .toml файл.\n",
        "    Печатает сводку.\n",
        "\n",
        "    ВХОДНЫЕ ДАННЫЕ:\n",
        "    - словарь config_dict\n",
        "\n",
        "    ВЫХОД:\n",
        "    - файл калибровки камеры в формате .toml\n",
        "    '''\n",
        "\n",
        "    # Чтение config_dict\n",
        "    project_dir = config_dict.get('project').get('project_dir')  # Получаем директорию проекта\n",
        "    # Находим директорию калибровки\n",
        "    calib_dir = [os.path.join(project_dir, c) for c in os.listdir(project_dir) if ('Calib' in c or 'calib' in c)][0]\n",
        "    calib_type = config_dict.get('calibration').get('calibration_type')  # Получаем тип калибровки\n",
        "\n",
        "    if calib_type == 'convert':\n",
        "        convert_filetype = config_dict.get('calibration').get('convert').get('convert_from')  # Получаем тип файла для конвертации\n",
        "        try:\n",
        "            if convert_filetype == 'qualisys':\n",
        "                convert_ext = '.qca.txt'  # Расширение для Qualisys\n",
        "                file_to_convert_path = glob.glob(os.path.join(calib_dir, f'*{convert_ext}*'))[0]  # Находим файл для конвертации\n",
        "                binning_factor = config_dict.get('calibration').get('convert').get('qualisys').get('binning_factor')  # Получаем фактор биннинга\n",
        "            elif convert_filetype == 'optitrack':\n",
        "                file_to_convert_path = ['']  # Пустой путь для OptiTrack\n",
        "                binning_factor = 1\n",
        "            elif convert_filetype == 'vicon':\n",
        "                convert_ext = '.xcp'  # Расширение для Vicon\n",
        "                file_to_convert_path = glob.glob(os.path.join(calib_dir, f'*{convert_ext}'))[0]\n",
        "                binning_factor = 1\n",
        "            elif convert_filetype == 'opencap':  # Все файлы с расширением .pickle\n",
        "                convert_ext = '.pickle'\n",
        "                file_to_convert_path = sorted(glob.glob(os.path.join(calib_dir, f'*{convert_ext}')))\n",
        "                binning_factor = 1\n",
        "            elif convert_filetype == 'easymocap':  # Файлы intri.yml\n",
        "                convert_ext = '.yml'\n",
        "                file_to_convert_path = sorted(glob.glob(os.path.join(calib_dir, f'*{convert_ext}')))\n",
        "                binning_factor = 1\n",
        "            elif convert_filetype == 'biocv':  # Все файлы без расширения -> теперь с расширением .calib\n",
        "                convert_ext = '.calib'\n",
        "                file_to_convert_path = sorted(glob.glob(os.path.join(calib_dir, f'*{convert_ext}')))\n",
        "                binning_factor = 1\n",
        "            elif convert_filetype in ['anipose', 'freemocap', 'caliscope']:  # Конвертация не требуется, пропускаем этот этап\n",
        "                logging.info(f'\\n--> Конвертация из Caliscope, AniPose или FreeMocap не требуется. Калибровка пропущена.\\n')\n",
        "                return\n",
        "            else:\n",
        "                convert_ext = '???'\n",
        "                file_to_convert_path = ['']\n",
        "                raise NameError(f'Конвертация калибровки из {convert_filetype} не поддерживается.') from None\n",
        "            assert file_to_convert_path != []\n",
        "        except:\n",
        "            raise NameError(f'Файл с расширением {convert_ext} не найден в {calib_dir}.')\n",
        "\n",
        "        calib_output_path = os.path.join(calib_dir, f'Calib_{convert_filetype}.toml')  # Путь для сохранения файла калибровки\n",
        "        calib_full_type = '_'.join([calib_type, convert_filetype])  # Полный тип калибровки\n",
        "        args_calib_fun = [file_to_convert_path, binning_factor]  # Аргументы для функции калибровки\n",
        "\n",
        "    elif calib_type == 'calculate':\n",
        "        intrinsics_config_dict = config_dict.get('calibration').get('calculate').get('intrinsics')  # Получаем параметры внутренней калибровки\n",
        "        extrinsics_config_dict = config_dict.get('calibration').get('calculate').get('extrinsics')  # Получаем параметры внешней калибровки\n",
        "        extrinsics_method = config_dict.get('calibration').get('calculate').get('extrinsics').get('extrinsics_method')  # Получаем метод внешней калибровки\n",
        "\n",
        "        calib_output_path = os.path.join(calib_dir, f'Calib_{extrinsics_method}.toml')  # Путь для сохранения файла калибровки\n",
        "        calib_full_type = calib_type  # Полный тип калибровки\n",
        "        args_calib_fun = [calib_dir, intrinsics_config_dict, extrinsics_config_dict]  # Аргументы для функции калибровки\n",
        "\n",
        "    else:\n",
        "        logging.info('Неверный тип калибровки в Config.toml')\n",
        "\n",
        "    # Сопоставление функции калибровки\n",
        "    '''\n",
        "\n",
        "    calib_mapping = {\n",
        "        'convert_qualisys': calib_qca_fun,\n",
        "        'convert_optitrack': calib_optitrack_fun,\n",
        "        'convert_vicon': calib_vicon_fun,\n",
        "        'convert_opencap': calib_opencap_fun,\n",
        "        'convert_easymocap': calib_easymocap_fun,\n",
        "        'convert_biocv': calib_biocv_fun,\n",
        "        'calculate': calib_calc_fun,\n",
        "    }\n",
        "    '''\n",
        "    calib_mapping = {\n",
        "        'calculate': calib_calc_fun,\n",
        "    }\n",
        "    calib_fun = calib_mapping[calib_full_type]  # Получаем соответствующую функцию калибровки\n",
        "\n",
        "    # Выполнение калибровки\n",
        "    ret, C, S, D, K, R, T = calib_fun(*args_calib_fun)\n",
        "\n",
        "    # Запись файла калибровки\n",
        "    toml_write(calib_output_path, C, S, D, K, R, T)\n",
        "\n",
        "    # Сообщение о результатах\n",
        "    recap_calibrate(ret, calib_output_path, calib_full_type)"
      ],
      "metadata": {
        "id": "x1jAgVGEu3mB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calibration(config=None):\n",
        "    '''\n",
        "    Калибровка камер с использованием шахматных досок или файлов Qualisys.\n",
        "\n",
        "    config может быть словарем,\n",
        "    или путем к директории испытания, участника или сессии,\n",
        "    или функция может быть вызвана без аргумента, в этом случае директория конфигурации будет текущей.\n",
        "    '''\n",
        "\n",
        "    #from Pose2Sim.calibration import calibrate_cams_all\n",
        "\n",
        "    # Чтение конфигурационных файлов и определение уровня\n",
        "    level, config_dicts = read_config_files(config, config_dir=config_dir)\n",
        "    config_dict = config_dicts[0]\n",
        "\n",
        "    try:\n",
        "        # Устанавливаем директорию сессии равной директории конфигурации\n",
        "        session_dir = config_dir\n",
        "\n",
        "        print('session_dir', session_dir)\n",
        "        # Поиск директории калибровки\n",
        "        [os.path.join(session_dir, c) for c in os.listdir(session_dir) if 'calib' in c.lower() and not c.lower().endswith('.py')][0]\n",
        "    except:\n",
        "        # Если не удалось найти директорию, используем текущую\n",
        "        session_dir = os.path.realpath(os.getcwd())\n",
        "\n",
        "    # Обновление словаря проекта с директорией сессии\n",
        "    config_dict.get(\"project\").update({\"project_dir\": session_dir})\n",
        "\n",
        "    # Настройка логирования\n",
        "    #setup_logging(session_dir)\n",
        "    currentDateAndTime = datetime.now()\n",
        "\n",
        "    # Запуск калибровки\n",
        "    # Поиск директории калибровки\n",
        "    print('session_dir', session_dir)\n",
        "    calib_dir = [os.path.join(session_dir, c) for c in os.listdir(session_dir) if os.path.isdir(os.path.join(session_dir, c)) and 'calib' in c.lower()][0]\n",
        "\n",
        "    # Логирование информации о калибровке\n",
        "    logging.info(\"\\n---------------------------------------------------------------------\")\n",
        "    logging.info(\"Калибровка камер\")\n",
        "    logging.info(f\"Дата и время: {currentDateAndTime.strftime('%A %d. %B %Y, %H:%M:%S')}\")\n",
        "    logging.info(f\"Директория калибровки: {calib_dir}\")\n",
        "    logging.info(\"---------------------------------------------------------------------\\n\")\n",
        "\n",
        "    # Запись времени начала калибровки\n",
        "    start = time.time()\n",
        "\n",
        "    # Выполнение калибровки камер\n",
        "    calibrate_cams_all(config_dict)\n",
        "\n",
        "    # Запись времени окончания калибровки\n",
        "    end = time.time()\n",
        "    # Логирование времени, затраченного на калибровку\n",
        "    logging.info(f'\\nКалибровка заняла {end-start:.2f} секунд.\\n')"
      ],
      "metadata": {
        "id": "YTw7FD8pl3Di"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calibration()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "8nbGQoztubvZ",
        "outputId": "8e97cdee-78b6-4ae1-96c7-1f4bc630ba06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "session_dir /content/pose2sim/Pose2Sim/Demo_SinglePerson/\n",
            "session_dir /content/pose2sim/Pose2Sim/Demo_SinglePerson/\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'convert_qualisys'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-197686a3ee59>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcalibration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-14-79611f3c607d>\u001b[0m in \u001b[0;36mcalibration\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;31m# Выполнение калибровки камер\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0mcalibrate_cams_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;31m# Запись времени окончания калибровки\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-d64989e362df>\u001b[0m in \u001b[0;36mcalibrate_cams_all\u001b[0;34m(config_dict)\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;34m'calculate'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcalib_calc_fun\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     }\n\u001b[0;32m---> 90\u001b[0;31m     \u001b[0mcalib_fun\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalib_mapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcalib_full_type\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Получаем соответствующую функцию калибровки\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;31m# Выполнение калибровки\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'convert_qualisys'"
          ]
        }
      ]
    }
  ]
}